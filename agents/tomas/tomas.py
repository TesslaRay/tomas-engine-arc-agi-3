import json
import os
import random
import re
import time
import base64
from typing import Any, Dict, List, Optional

from ..agent import Agent
from ..structs import FrameData, GameAction, GameState

# utils
from ..image_utils import grid_to_image

# services
from ..services.gemini_service import GeminiService
from ..services.cerebras_service import CerebrasService

# modules
from ..tomas_engine.spatial_perception_module import SpatialPerceptionModule
from ..tomas_engine.constants import get_action_name


class Tomas(Agent):
    """Tomas agent"""

    MAX_ACTIONS = 20

    def __init__(self, *args: Any, llm_provider: str = "gemini", **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)

        print(f"üß† Starting Tomas")

        # Initialize Gemini service
        try:
            self.gemini_service = GeminiService()
            print("‚úÖ Gemini service initialized")

            self.cerebras = CerebrasService()
            print("‚úÖ Cerebras service initialized")
        except Exception as e:
            print(f"‚ö†Ô∏è Error initializing Gemini: {e}")
            self.gemini_service = None

        # Initialize spatial perception module
        try:
            self.spatial_perception = SpatialPerceptionModule(provider=llm_provider)
            print(f"‚úÖ Perception module initialized with {llm_provider.upper()}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error initializing spatial perception: {e}")
            self.spatial_perception = None

        # Initialize episodic memory
        self.episodic_memory: List[Dict[str, Any]] = []
        self.max_memory_size = 10  # Keep last 10 moves

        # Store last 3 images for analysis
        self.recent_images: List[Any] = []  # PIL Images
        self.max_images = 3

        # Global vector cognition memory
        self.vcg_history: List[Dict[str, Any]] = []
        self.max_vcg_history = 5  # Keep last 5 VCGs

        # Previous board state for differential analysis
        # Initialize with dummy matrix "closed eyes" (64x64 of zeros)
        self.previous_board_state = self._create_dummy_closed_eyes_matrix()
        self.previous_frame_data = None

        # Previous action information for spatial analysis
        self.previous_action = None
        self.previous_action_coordinates = None

        # LOGOS orders queue
        self.pending_orders = []  # Pending orders
        self.current_order_index = 0  # Current order index
        self.orders_reasoning = ""  # Reasoning for the sequence of orders

        print(
            f"üëÅÔ∏è Closed eyes matrix initialized: {len(self.previous_board_state)}x{len(self.previous_board_state[0])} (all black)"
        )
        print(f"üìã LOGOS orders queue initialized: 0 pending orders")

    def _create_dummy_closed_eyes_matrix(self) -> List[List[int]]:
        """
        Create dummy matrix that represents "closed eyes"

        This matrix is used as the initial "previous" state for the spatial analysis
        to work from the first turn of the game.

        Returns:
            Matrix 64x64 filled with 16 (pink)
        """
        return [[16 for _ in range(64)] for _ in range(64)]

    def add_orders_from_logos(
        self, orders_list: List[Dict[str, Any]], reasoning: str = ""
    ) -> None:
        """
        Agregar una secuencia de √≥rdenes de LOGOS para ejecutar

        Args:
            orders_list: Lista de √≥rdenes con formato [{"action": "move_up", "coordinates": (x, y)}, ...]
            reasoning: Razonamiento detr√°s de la secuencia de √≥rdenes
        """
        self.pending_orders = orders_list.copy()
        self.current_order_index = 0
        self.orders_reasoning = reasoning

        print(f"\nüìã === LOGOS HA EMITIDO {len(orders_list)} √ìRDENES ===")
        for i, order in enumerate(orders_list, 1):
            action_name = order.get("action", "unknown")
            coords = order.get("coordinates")
            coord_info = f" en {coords}" if coords else ""
            print(f"   {i}. {action_name}{coord_info}")
        print(f"üéØ Razonamiento: {reasoning}")
        print("=" * 50)

    def has_pending_orders(self) -> bool:
        """
        Verificar si hay √≥rdenes pendientes por ejecutar

        Returns:
            True si hay √≥rdenes pendientes, False si no
        """
        return self.pending_orders and self.current_order_index < len(
            self.pending_orders
        )

    def get_next_order(self) -> Optional[Dict[str, Any]]:
        """
        Obtener la siguiente orden a ejecutar

        Returns:
            Diccionario con la orden o None si no hay m√°s √≥rdenes
        """
        if self.has_pending_orders():
            current_order = self.pending_orders[self.current_order_index]
            self.current_order_index += 1

            print(
                f"\n‚ö° EJECUTANDO ORDEN {self.current_order_index}/{len(self.pending_orders)}"
            )
            print(f"   üéØ Acci√≥n: {current_order.get('action', 'unknown')}")
            if "coordinates" in current_order:
                print(f"   üìç Coordenadas: {current_order['coordinates']}")
            print(
                f"   üìã √ìrdenes restantes: {len(self.pending_orders) - self.current_order_index}"
            )

            return current_order
        return None

    def clear_orders(self) -> None:
        """
        Limpiar todas las √≥rdenes pendientes
        """
        orders_completed = self.current_order_index
        total_orders = len(self.pending_orders)

        self.pending_orders = []
        self.current_order_index = 0
        self.orders_reasoning = ""

        print(f"\n‚úÖ === SECUENCIA DE √ìRDENES COMPLETADA ===")
        print(f"üìä √ìrdenes ejecutadas: {orders_completed}/{total_orders}")
        print(
            f"üîÑ Regresando al flujo cognitivo completo: Spatial Perception ‚Üí APEIRON ‚Üí SOPHIA ‚Üí LOGOS"
        )
        print("=" * 50)

    def _execute_pending_order(self) -> GameAction:
        """
        Ejecutar la siguiente orden pendiente de LOGOS

        Returns:
            GameAction correspondiente a la orden pendiente
        """
        next_order = self.get_next_order()

        if not next_order:
            # No hay m√°s √≥rdenes v√°lidas, esto no deber√≠a pasar
            print(
                "‚ùå Error: se llam√≥ _execute_pending_order pero no hay √≥rdenes v√°lidas"
            )
            self.clear_orders()
            # En lugar de aleatorio, fallback que nunca deber√≠a ejecutarse
            action = GameAction.ACTION1  # Solo como fallback de emergencia
            action.reasoning = (
                "Error interno: orden inv√°lida, requiere revisi√≥n del c√≥digo"
            )
            return action

        # Mapear la orden a GameAction
        action_command = next_order.get("action", "").lower()
        action_map = {
            "move_up": 1,
            "move_down": 2,
            "move_left": 3,
            "move_right": 4,
            "space": 5,
            "click": 6,
        }

        suggested_action_number = action_map.get(action_command)

        if suggested_action_number:
            action = self._map_action_number_to_game_action(suggested_action_number)

            # Configurar reasoning con informaci√≥n de la secuencia
            remaining_orders = len(self.pending_orders) - self.current_order_index
            action.reasoning = {
                "execution_mode": "ORDEN_SECUENCIAL_LOGOS",
                "orden_actual": f"{self.current_order_index}/{len(self.pending_orders)}",
                "accion_ejecutada": action_command,
                "ordenes_restantes": remaining_orders,
                "razonamiento_secuencia": self.orders_reasoning,
                "coordinates": next_order.get("coordinates"),
            }

            # Configurar coordenadas si es una acci√≥n compleja
            if action.is_complex() and "coordinates" in next_order:
                coords = next_order["coordinates"]
                if isinstance(coords, (list, tuple)) and len(coords) >= 2:
                    action.set_data({"x": coords[0], "y": coords[1]})
                else:
                    # Fallback a coordenadas aleatorias si las coordenadas no son v√°lidas
                    action.set_data(
                        {"x": random.randint(0, 63), "y": random.randint(0, 63)}
                    )

            # Si esta es la √∫ltima orden, informar sobre el pr√≥ximo flujo
            if not self.has_pending_orders():
                print(f"\nüèÅ Esta fue la √öLTIMA orden de la secuencia")
                print(
                    f"üîÑ En el pr√≥ximo turno: Spatial Perception analizar√° TODOS los cambios acumulados"
                )
                print(
                    f"   ‚Üí APEIRON ver√° la historia completa de las √≥rdenes ejecutadas"
                )

            print(
                f"\n‚ö° EJECUTANDO: {action_command} (orden {self.current_order_index}/{len(self.pending_orders)})"
            )
            return action
        else:
            # Acci√≥n no reconocida
            print(f"‚ùå Acci√≥n no reconocida en orden: '{action_command}'")
            print(f"üîÑ Limpiando cola de √≥rdenes y regresando al flujo completo")
            self.clear_orders()
            # En lugar de aleatorio, forzar el flujo completo en el siguiente choose_action
            action = GameAction.ACTION1  # Fallback temporal
            action.reasoning = f"Error: acci√≥n no reconocida '{action_command}', regresando al flujo completo"
            return action

    def load_markdown_file(self, file_path: str) -> str:
        """
        Cargar un archivo markdown de forma gen√©rica

        Args:
            file_path: Ruta relativa al archivo .md desde el directorio tomas/

        Returns:
            Contenido del archivo como string
        """
        try:
            # Obtener la ruta del directorio actual del archivo
            current_dir = os.path.dirname(os.path.abspath(__file__))
            full_path = os.path.join(current_dir, file_path)

            if not os.path.exists(full_path):
                print(f"‚ö†Ô∏è Archivo {file_path} no encontrado en: {full_path}")
                return f"# Error: Archivo {file_path} no encontrado"

            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read()

            print(f"‚úÖ Archivo {file_path} cargado correctamente")
            return content

        except Exception as e:
            print(f"‚ö†Ô∏è Error al cargar {file_path}: {e}")
            return f"# Error: No se pudo cargar {file_path}"

    def analyze_spatial_perception(self, current_frame: FrameData) -> Optional[str]:
        """
        Realizar an√°lisis de percepci√≥n espacial comparando el estado actual con el anterior

        Args:
            current_frame: Estado actual del juego

        Returns:
            An√°lisis espacial como string o None si no hay an√°lisis disponible
        """
        if not self.spatial_perception or current_frame.is_empty():
            return None

        # NOTA: Ya no verificamos self.previous_board_state porque siempre tenemos la matriz dummy

        try:
            print(f"\nüé® === INICIANDO AN√ÅLISIS DE PERCEPCI√ìN ESPACIAL ===")

            # Determinar si es el primer turno (comparando con matriz dummy)
            is_first_turn = all(
                all(cell == 0 for cell in row) for row in self.previous_board_state
            )

            if is_first_turn:
                print(
                    f"üëÅÔ∏è PRIMER TURNO: Comparando matriz actual vs 'ojos cerrados' (dummy)"
                )
            else:
                print(f"üîÑ TURNO SUBSECUENTE: Comparando estado actual vs anterior")

            # Realizar an√°lisis de efectos de la acci√≥n anterior
            analysis_result = self.spatial_perception.analyze_action_effect(
                matrix_before=self.previous_board_state,
                matrix_after=current_frame.frame,
                action=self.previous_action if self.previous_action else 0,
                coordinates=self.previous_action_coordinates,
                include_visual_interpretation=True,  # Incluir an√°lisis visual de Gemini
            )

            print(f"‚úÖ An√°lisis espacial completado")
            print(f"üìä Resultado: {len(analysis_result)} caracteres")
            print(f"üîç An√°lisis detallado:")
            print("=" * 50)
            print(analysis_result)
            print("=" * 50)

            return analysis_result

        except Exception as e:
            print(f"‚ùå Error en an√°lisis de percepci√≥n espacial: {e}")
            return None

    def ask_apeiron_analysis(
        self,
        latest_frame: FrameData,
        vector_cognitivo_global_anterior: Optional[str] = None,
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Consultar a APEIRON (LLM1) para an√°lisis perceptual

        Args:
            latest_frame: Estado actual del frame
            vector_cognitivo_global_anterior: VCG del turno anterior (opcional)

        Returns:
            Tupla con (respuesta_completa, json_extraido)
        """
        if not self.gemini_service or latest_frame.is_empty():
            return "An√°lisis no disponible", None

        try:
            # Cargar los archivos necesarios
            alma_content = self.load_markdown_file("alma.md")
            apeiron_system_prompt = self.load_markdown_file(
                "processus/apeiron/system-prompt.md"
            )
            apeiron_response_format = self.load_markdown_file(
                "processus/apeiron/response.md"
            )

            # Realizar an√°lisis de percepci√≥n espacial si hay estado anterior
            spatial_analysis = self.analyze_spatial_perception(latest_frame)

            # Determinar si es el primer turno para contexto adicional
            is_first_turn = all(
                all(cell == 0 for cell in row) for row in self.previous_board_state
            )
            first_turn_context = ""
            if is_first_turn:
                first_turn_context = """
## CONTEXTO ESPECIAL - PRIMER TURNO:
Este es el primer turno del juego. El an√°lisis de percepci√≥n espacial compara el estado actual del tablero contra una matriz "ojos cerrados" (todo en negro/ceros). Esto significa que TODAS las figuras/objetos visibles en el tablero actual son NUEVAS APARICIONES desde el estado inicial de "ojos cerrados".

El an√°lisis espacial detectar√° todos los elementos del tablero como "apariciones" o "materializaciones" desde el estado de oscuridad total.
"""

            # Construir el prompt combinado
            combined_prompt = f"""
{alma_content}

{apeiron_system_prompt}

{apeiron_response_format}

## ESTADO ACTUAL DEL JUEGO:
- Puntuaci√≥n: {latest_frame.score}
- Acci√≥n n√∫mero: {self.action_counter}
- Estado del juego: {latest_frame.state}

{first_turn_context}

## input_fresco (board_state actual):
{latest_frame.frame}

## board_state_anterior (para an√°lisis diferencial):
{self.previous_board_state if self.previous_board_state is not None else "Este es el primer turno - no hay estado anterior"}

## vector_cognitivo_global_anterior:
{vector_cognitivo_global_anterior if vector_cognitivo_global_anterior else "Este es el primer turno - no hay VCG anterior"}

## analisis_percepcion_espacial:
{spatial_analysis if spatial_analysis else "No hay an√°lisis espacial disponible - primer turno o sin cambios"}

IMPORTANTE: Tu respuesta DEBE ser un JSON v√°lido que incluya el campo "timestamp" en formato ISO 8601 (ejemplo: "2025-08-05T10:30:00.000Z"). Genera el timestamp actual autom√°ticamente.
"""

            print(f"\nüß† === CONSULTANDO APEIRON (LLM1) ===")
            print(f"üéØ Fase: An√°lisis Perceptual")

            # Log de entrada
            print(f"\nüì• ENTRADA APEIRON:")
            print(f"   üìÑ Alma: {len(alma_content)} chars")
            print(f"   üìÑ System Prompt: {len(apeiron_system_prompt)} chars")
            print(f"   üìÑ Response Format: {len(apeiron_response_format)} chars")
            print(
                f"   üéÆ Frame Data: {latest_frame.frame.shape if hasattr(latest_frame.frame, 'shape') else 'N/A'}"
            )
            print(
                f"   üìä VCG Anterior: {len(vector_cognitivo_global_anterior) if vector_cognitivo_global_anterior else 0} chars"
            )
            print(
                f"   üé® Percepci√≥n Espacial: {len(spatial_analysis) if spatial_analysis else 0} chars"
            )
            print(f"   üìù Prompt Total: {len(combined_prompt)} chars")

            response = self.gemini_service.generate_with_images_sync(
                prompt=combined_prompt,
                images=[],  # Sin im√°genes por ahora, solo matriz
                system_prompt=alma_content,
            )

            # Log de salida
            print(f"\nüì§ SALIDA APEIRON:")
            print(f"   ‚úÖ Completado en {response.duration_ms}ms")
            print(f"   üé´ Tokens: {response.usage['total_tokens']}")
            print(f"   üìù Respuesta: {len(response.content)} chars")
            print(f"   üìÑ Contenido completo:")
            print(f"{response.content}")

            # Extraer JSON de la respuesta
            extracted_json = self.extract_json_from_llm_response(
                response.content, "apeiron"
            )

            return response.content, extracted_json

        except Exception as e:
            print(f"‚ùå Error en APEIRON: {e}")
            return f"Error en APEIRON: {str(e)}", None

    def ask_sophia_analysis(
        self, apeiron_response: str
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Consultar a SOPHIA (LLM2) para an√°lisis epist√©mico

        Args:
            apeiron_response: Respuesta completa de APEIRON del turno actual

        Returns:
            Tupla con (respuesta_completa, json_extraido)
        """
        if not self.gemini_service:
            return "An√°lisis no disponible", None

        try:
            # Cargar los archivos necesarios
            alma_content = self.load_markdown_file("alma.md")
            sophia_system_prompt = self.load_markdown_file(
                "processus/sophia/system-prompt.md"
            )
            sophia_response_format = self.load_markdown_file(
                "processus/sophia/response.md"
            )

            # Construir el prompt combinado
            combined_prompt = f"""
{alma_content}

{sophia_system_prompt}

{sophia_response_format}

## Vector Cognitivo Global actualizado por APEIRON:
{apeiron_response}

IMPORTANTE: Tu respuesta DEBE ser un JSON v√°lido que incluya el campo "timestamp" en formato ISO 8601 (ejemplo: "2025-08-05T10:30:00.000Z"). Genera el timestamp actual autom√°ticamente.
"""

            print(f"\nüß† === CONSULTANDO SOPHIA (LLM2) ===")
            print(f"üéØ Fase: An√°lisis Epist√©mico")

            # Log de entrada
            print(f"\nüì• ENTRADA SOPHIA:")
            print(f"   üìÑ Alma: {len(alma_content)} chars")
            print(f"   üìÑ System Prompt: {len(sophia_system_prompt)} chars")
            print(f"   üìÑ Response Format: {len(sophia_response_format)} chars")
            print(f"   üß† Respuesta APEIRON: {len(apeiron_response)} chars")
            print(f"   üìù Prompt Total: {len(combined_prompt)} chars")

            # response = self.gemini_service.generate_with_images_sync(
            #     prompt=combined_prompt,
            #     images=[],  # Sophia no necesita im√°genes, trabaja con conceptos
            #     system_prompt=alma_content,
            # )
            response = self.cerebras.generate_text_sync(
                prompt=combined_prompt,
                system_prompt=alma_content,
            )

            # Log de salida
            print(f"\nüì§ SALIDA SOPHIA:")
            print(f"   ‚úÖ Completado en {response.duration_ms}ms")
            print(f"   üé´ Tokens: {response.usage['total_tokens']}")
            print(f"   üìù Respuesta: {len(response.content)} chars")
            print(f"   üìÑ Contenido completo:")
            print(f"{response.content}")

            # Extraer JSON de la respuesta
            extracted_json = self.extract_json_from_llm_response(
                response.content, "sophia"
            )

            return response.content, extracted_json

        except Exception as e:
            print(f"‚ùå Error en SOPHIA: {e}")
            return f"Error en SOPHIA: {str(e)}", None

    def ask_logos_analysis(
        self, sophia_response: str
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Consultar a LOGOS (LLM3) para deliberaci√≥n y acci√≥n

        Args:
            sophia_response: Respuesta completa de SOPHIA del turno actual

        Returns:
            Tupla con (respuesta_completa, json_extraido)
        """
        if not self.gemini_service:
            return "An√°lisis no disponible", None

        try:
            # Cargar los archivos necesarios
            alma_content = self.load_markdown_file("alma.md")
            logos_system_prompt = self.load_markdown_file(
                "processus/logos/system-prompt.md"
            )
            logos_response_format = self.load_markdown_file(
                "processus/logos/response.md"
            )

            # Construir el prompt combinado
            combined_prompt = f"""
{alma_content}

{logos_system_prompt}

{logos_response_format}

## Vector Cognitivo Global enriquecido por SOPHIA:
{sophia_response}

IMPORTANTE: Tu respuesta DEBE ser un JSON v√°lido que incluya el campo "timestamp" en formato ISO 8601 (ejemplo: "2025-08-05T10:30:00.000Z"). Genera el timestamp actual autom√°ticamente.
"""

            print(f"\nüß† === CONSULTANDO LOGOS (LLM3) ===")
            print(f"üéØ Fase: Deliberaci√≥n y Acci√≥n")

            # Log de entrada
            print(f"\nüì• ENTRADA LOGOS:")
            print(f"   üìÑ Alma: {len(alma_content)} chars")
            print(f"   üìÑ System Prompt: {len(logos_system_prompt)} chars")
            print(f"   üìÑ Response Format: {len(logos_response_format)} chars")
            print(f"   üß† Respuesta SOPHIA: {len(sophia_response)} chars")
            print(f"   üìù Prompt Total: {len(combined_prompt)} chars")

            # response = self.gemini_service.generate_with_images_sync(
            #     prompt=combined_prompt,
            #     images=[],  # Logos no necesita im√°genes, trabaja con estrategia
            #     system_prompt=alma_content,
            # )
            response = self.cerebras.generate_text_sync(
                prompt=combined_prompt,
                system_prompt=alma_content,
            )

            # Log de salida
            print(f"\nüì§ SALIDA LOGOS:")
            print(f"   ‚úÖ Completado en {response.duration_ms}ms")
            print(f"   üé´ Tokens: {response.usage['total_tokens']}")
            print(f"   üìù Respuesta: {len(response.content)} chars")
            print(f"   üìÑ Contenido completo:")
            print(f"{response.content}")

            # Extraer JSON de la respuesta
            extracted_json = self.extract_json_from_llm_response(
                response.content, "logos"
            )

            return response.content, extracted_json

        except Exception as e:
            print(f"‚ùå Error en LOGOS: {e}")
            return f"Error en LOGOS: {str(e)}", None

    def extract_json_from_llm_response(
        self, llm_response: str, llm_type: str
    ) -> Optional[Dict[str, Any]]:
        """
        Extrae el JSON de la respuesta del LLM seg√∫n el tipo (apeiron, sophia, logos)

        Args:
            llm_response: Respuesta completa del LLM
            llm_type: Tipo de LLM ("apeiron", "sophia", "logos")

        Returns:
            Diccionario con el JSON extra√≠do o None si no se encuentra
        """
        try:
            # Buscar el JSON principal usando un enfoque m√°s preciso
            # Primero intentar encontrar bloques JSON con llaves balanceadas
            json_start = llm_response.find("{")
            if json_start == -1:
                print(f"‚ùå No se encontr√≥ JSON en la respuesta de {llm_type.upper()}")
                return None

            # Buscar el JSON completo balanceando llaves
            brace_count = 0
            json_end = json_start
            for i, char in enumerate(llm_response[json_start:], json_start):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break

            if brace_count != 0:
                print(
                    f"‚ùå JSON mal formateado en {llm_type.upper()} - llaves no balanceadas"
                )
                return None

            # Extraer el JSON completo
            json_text = llm_response[json_start:json_end]

            try:
                parsed_json = json.loads(json_text)

                # Definir campos requeridos seg√∫n el tipo de LLM
                required_fields = {
                    "apeiron": [
                        "timestamp",
                        "causal_narrative_of_turn",
                        "conceptualized_entities",
                        "new_turn_learnings",
                        "synthesis_for_next_cycle",
                    ],
                    "sophia": [
                        "timestamp",
                        "epistemic_analysis",
                        "archetype_analysis",
                        "verified_game_rules",
                        "global_game_theories",
                    ],
                    "logos": [
                        "timestamp",
                        "intent_phase",
                        "counsel_phase",
                        "choice_phase",
                        "command_phase",
                        "predictive_judgment_phase",
                    ],
                }

                target_fields = required_fields.get(llm_type, [])

                # Validar que tenga los campos requeridos seg√∫n el tipo
                if all(field in parsed_json for field in target_fields):
                    print(f"‚úÖ JSON v√°lido extra√≠do de {llm_type.upper()}")
                    return parsed_json
                else:
                    print(
                        f"‚ö†Ô∏è JSON de {llm_type.upper()} no tiene todos los campos requeridos"
                    )
                    print(f"   Esperados: {target_fields}")
                    print(f"   Encontrados: {list(parsed_json.keys())}")
                    return None

            except json.JSONDecodeError as e:
                print(f"‚ùå Error al parsear JSON de {llm_type.upper()}: {e}")
                return None

        except Exception as e:
            print(f"‚ùå Error al extraer JSON de {llm_type.upper()}: {e}")
            return None

    def llmJsonExtractor(self, llm_response: str) -> Optional[Dict[str, Any]]:
        """
        M√©todo legacy - mantener para compatibilidad
        """
        return self.extract_json_from_llm_response(llm_response, "logos")

    def _map_action_number_to_game_action(self, action_number: int) -> GameAction:
        """
        Mapear n√∫mero de acci√≥n del JSON a GameAction

        Args:
            action_number: N√∫mero de acci√≥n (1-6)

        Returns:
            GameAction correspondiente
        """
        action_map = {
            1: GameAction.ACTION1,  # Arriba
            2: GameAction.ACTION2,  # Abajo
            3: GameAction.ACTION3,  # Izquierda
            4: GameAction.ACTION4,  # Derecha
            5: GameAction.ACTION5,  # Barra espaciadora
            6: GameAction.ACTION6,  # Click del mouse
        }

        return action_map.get(
            action_number, GameAction.ACTION1
        )  # Default a ACTION1 si no se encuentra

    def add_to_episodic_memory(
        self,
        action: GameAction,
        frame_before: FrameData,
        frame_after: FrameData,
        gemini_analysis: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        Agregar un movimiento a la memoria epis√≥dica

        Args:
            action: Acci√≥n tomada
            frame_before: Estado del juego antes de la acci√≥n
            frame_after: Estado del juego despu√©s de la acci√≥n
            gemini_analysis: An√°lisis de Gemini para esta acci√≥n
        """
        memory_entry = {
            "action_number": self.action_counter,
            "action": action.value,
            "action_name": self._get_action_name(action.value),
            "score_before": frame_before.score,
            "score_after": frame_after.score,
            "score_change": frame_after.score - frame_before.score,
            "game_state_before": frame_before.state.value,
            "game_state_after": frame_after.state.value,
            "gemini_reasoning": (
                gemini_analysis.get("current_hypothesis", "") if gemini_analysis else ""
            ),
            "timestamp": time.time(),
        }

        # Agregar a la memoria
        self.episodic_memory.append(memory_entry)

        # Mantener solo los √∫ltimos N movimientos
        if len(self.episodic_memory) > self.max_memory_size:
            self.episodic_memory.pop(0)

        print(f"üìù Memoria actualizada: {len(self.episodic_memory)} entradas")

    def _get_action_name(self, action_value: int) -> str:
        """Convertir n√∫mero de acci√≥n a nombre legible"""
        # Usar las constantes centralizadas pero con nombres en espa√±ol
        spanish_names = {
            0: "RESET",
            1: "Arriba",
            2: "Abajo",
            3: "Izquierda",
            4: "Derecha",
            5: "Barra",
            6: "Click",
        }
        return spanish_names.get(action_value, f"Acci√≥n {action_value}")

    def get_memory_summary(self) -> str:
        """
        Generar un resumen de la memoria epis√≥dica para el prompt de Gemini

        Returns:
            String con resumen de movimientos recientes
        """
        if not self.episodic_memory:
            return (
                "## Historial de Movimientos\nEste es el primer movimiento del juego."
            )

        summary = "## Historial de Movimientos Recientes\n\n"

        for i, entry in enumerate(
            self.episodic_memory[-5:], 1
        ):  # √öltimos 5 movimientos
            score_indicator = ""
            if entry["score_change"] > 0:
                score_indicator = f" (+{entry['score_change']} puntos ‚úÖ)"
            elif entry["score_change"] < 0:
                score_indicator = f" ({entry['score_change']} puntos ‚ùå)"
            else:
                score_indicator = " (sin cambio de puntuaci√≥n)"

            summary += f"**Movimiento {entry['action_number']}:** {entry['action_name']}{score_indicator}\n"
            if entry["gemini_reasoning"]:
                summary += f"- Razonamiento: {entry['gemini_reasoning']}\n"
            summary += f"- Estado: {entry['game_state_before']} ‚Üí {entry['game_state_after']}\n\n"

        # Agregar an√°lisis de patrones
        if len(self.episodic_memory) >= 3:
            recent_scores = [
                entry["score_change"] for entry in self.episodic_memory[-3:]
            ]
            if all(s >= 0 for s in recent_scores):
                summary += "üéØ **Patr√≥n observado:** Los √∫ltimos movimientos han sido exitosos o neutrales.\n"
            elif all(s <= 0 for s in recent_scores):
                summary += "‚ö†Ô∏è **Patr√≥n observado:** Los √∫ltimos movimientos no han mejorado la puntuaci√≥n.\n"

        return summary

    def add_image_to_history(self, image) -> None:
        """
        Agregar imagen al historial de im√°genes recientes

        Args:
            image: PIL Image object
        """
        self.recent_images.append(image)

        # Mantener solo las √∫ltimas 3 im√°genes
        if len(self.recent_images) > self.max_images:
            self.recent_images.pop(0)

        print(
            f"üì∏ Historial de im√°genes actualizado: {len(self.recent_images)} im√°genes"
        )

    def display_image_in_iterm2(self, image) -> None:
        """
        Mostrar imagen directamente en iTerm2 usando secuencias de escape

        Args:
            image: PIL Image object (ya viene escalada 5x desde grid_to_image)
        """
        try:
            import io

            # Convertir imagen a bytes
            img_buffer = io.BytesIO()
            image.save(img_buffer, format="PNG")
            img_data = img_buffer.getvalue()

            # Codificar en base64
            img_base64 = base64.b64encode(img_data).decode("utf-8")

            # Secuencia de escape de iTerm2 para mostrar imagen
            print(f"\033]1337;File=inline=1:{img_base64}\a")

        except Exception as e:
            print(f"‚ö†Ô∏è Error al mostrar imagen en iTerm2: {e}")

    def display_recent_images_in_iterm2(self) -> None:
        """
        Mostrar las im√°genes recientes disponibles en iTerm2
        """
        if not self.recent_images:
            print("üì∏ No hay im√°genes en el historial")
            return

        print(f"üñºÔ∏è === MAPAS RECIENTES ({len(self.recent_images)} im√°genes) ===")

        for i, image in enumerate(self.recent_images):
            if i == len(self.recent_images) - 1:
                print(f"üìç Mapa actual (turno {self.action_counter}):")
            else:
                print(f"üìú Mapa anterior {i+1}:")

            self.display_image_in_iterm2(image)
            print()

        print("=" * 50)

    @property
    def name(self) -> str:
        return f"{super().name}.{self.MAX_ACTIONS}"

    def is_done(self, frames: list[FrameData], latest_frame: FrameData) -> bool:
        """Decide if the agent is done playing or not."""
        return any(
            [
                latest_frame.state is GameState.WIN,
                # uncomment to only let the agent play one time
                # latest_frame.state is GameState.GAME_OVER,
            ]
        )

    def show_current_map(self, latest_frame: FrameData) -> None:
        """Display the current map state as an image and save it."""
        print(f"\n=== ESTADO ACTUAL DEL MAPA ===")
        print(f"Estado del juego: {latest_frame.state}")
        print(f"Puntuaci√≥n: {latest_frame.score}")
        print(f"Acci√≥n n√∫mero: {self.action_counter}")

        if latest_frame.is_empty():
            print("Mapa vac√≠o - no hay datos para mostrar")
            return

        # Convertir el mapa a imagen
        map_image = grid_to_image(latest_frame.frame)

        # Crear directorio images si no existe
        import os

        os.makedirs("images", exist_ok=True)

        # Guardar la imagen con informaci√≥n del estado
        filename = f"images/tomas_map_action_{self.action_counter:03d}_score_{latest_frame.score:03d}.png"
        map_image.save(filename)

        print(f"Imagen del mapa guardada como: {filename}")
        print(f"Dimensiones de la imagen: {map_image.size}")
        print("=" * 40)

        return map_image

    def ask_gemini_analysis(
        self, latest_frame: FrameData
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Ejecutar el flujo secuencial APEIRON ‚Üí SOPHIA ‚Üí LOGOS

        Returns:
            Tupla con (respuesta_completa_de_logos, json_extraido_de_logos)
        """
        if not self.gemini_service or latest_frame.is_empty():
            return "An√°lisis no disponible", None

        try:
            # Generar imagen del mapa actual (comentado por ahora)
            # map_image = grid_to_image(latest_frame.frame)

            # Agregar imagen actual al historial (comentado por ahora)
            # self.add_image_to_history(map_image)

            # Mostrar im√°genes recientes en iTerm2 (comentado por ahora)
            # self.display_recent_images_in_iterm2()

            print(f"\nüß† === INICIANDO FLUJO COGNITIVO TOMAS ===")
            print(f"üéØ Turno {self.action_counter} | Puntuaci√≥n: {latest_frame.score}")
            print(f"üîÑ Flujo: APEIRON ‚Üí SOPHIA ‚Üí LOGOS")
            print("=" * 60)

            # Guardar el estado actual como "anterior" para el pr√≥ximo turno
            # (Esto se hace al INICIO del turno, no al final)

            # Obtener VCG anterior si existe
            vector_cognitivo_global_anterior = (
                self.get_vector_cognitivo_global_anterior()
            )

            # Debug: mostrar si tenemos VCG anterior
            if vector_cognitivo_global_anterior:
                print(
                    f"üìö VCG Anterior disponible: {len(vector_cognitivo_global_anterior)} chars"
                )
            else:
                print(f"üìö Primer turno - No hay VCG anterior")

            # PASO 1: APEIRON - An√°lisis Perceptual
            apeiron_response, apeiron_json = self.ask_apeiron_analysis(
                latest_frame, vector_cognitivo_global_anterior
            )

            if not apeiron_json:
                print(
                    "‚ö†Ô∏è APEIRON no devolvi√≥ JSON v√°lido, continuando con respuesta textual"
                )

            # PASO 2: SOPHIA - An√°lisis Epist√©mico
            sophia_response, sophia_json = self.ask_sophia_analysis(apeiron_response)

            if not sophia_json:
                print(
                    "‚ö†Ô∏è SOPHIA no devolvi√≥ JSON v√°lido, continuando con respuesta textual"
                )

            # PASO 3: LOGOS - Deliberaci√≥n y Acci√≥n
            logos_response, logos_json = self.ask_logos_analysis(sophia_response)

            if not logos_json:
                print("‚ö†Ô∏è LOGOS no devolvi√≥ JSON v√°lido")

            print(f"\n‚úÖ === FLUJO COGNITIVO COMPLETADO ===")
            print(f"üìä Total de pasos ejecutados: APEIRON ‚úÖ | SOPHIA ‚úÖ | LOGOS ‚úÖ")
            print("=" * 60)

            # Guardar el VCG completo para el pr√≥ximo turno
            # IMPORTANTE: Guardamos el estado ACTUAL como referencia para el PR√ìXIMO turno
            self.previous_frame_data = latest_frame
            self.previous_board_state = latest_frame.frame
            self.save_vector_cognitivo_global(
                apeiron_response, sophia_response, logos_response
            )

            # Retornar la respuesta de LOGOS (que contiene la decisi√≥n de acci√≥n)
            return logos_response, logos_json

        except Exception as e:
            print(f"‚ùå Error en flujo TOMAS: {e}")
            return f"Error en flujo TOMAS: {str(e)}", None

    def get_vector_cognitivo_global_anterior(self) -> Optional[str]:
        """
        Obtener el Vector Cognitivo Global completo del turno anterior
        """
        if not self.vcg_history:
            return None

        # Obtener el VCG m√°s reciente
        last_vcg = self.vcg_history[-1]

        # Construir el VCG anterior con toda la informaci√≥n
        vcg_anterior = f"""
## Vector Cognitivo Global del Turno Anterior (Turno {last_vcg['turno']})

### Estado LLM1 (APEIRON - Percepci√≥n anterior):
{last_vcg['apeiron_response']}

### Estado LLM2 (SOPHIA - Abstracci√≥n anterior):
{last_vcg['sophia_response']}

### Estado LLM3 (LOGOS - Deliberaci√≥n anterior):
{last_vcg['logos_response']}

### board_state anterior:
{last_vcg['board_state']}

### Contexto del turno:
- Puntuaci√≥n: {last_vcg['score']}
- Estado del juego: {last_vcg['game_state']}
- Timestamp: {last_vcg['timestamp']}
"""
        return vcg_anterior

    def save_vector_cognitivo_global(
        self, apeiron_response: str, sophia_response: str, logos_response: str
    ) -> None:
        """
        Guardar el Vector Cognitivo Global completo del turno actual con toda la informaci√≥n
        """
        try:
            print(f"\nüíæ === GUARDANDO VCG TURNO {self.action_counter} ===")

            # Crear VCG completo con toda la informaci√≥n necesaria
            vcg_completo = {
                "turno": self.action_counter,
                "timestamp": time.time(),
                "apeiron_response": apeiron_response,
                "sophia_response": sophia_response,
                "logos_response": logos_response,
                "board_state": (
                    str(self.previous_frame_data.frame)
                    if self.previous_frame_data
                    else "N/A"
                ),
                "score": (
                    self.previous_frame_data.score if self.previous_frame_data else 0
                ),
                "game_state": (
                    str(self.previous_frame_data.state)
                    if self.previous_frame_data
                    else "UNKNOWN"
                ),
            }

            # Agregar a la historia de VCG
            self.vcg_history.append(vcg_completo)

            # Mantener solo los √∫ltimos N VCG
            if len(self.vcg_history) > self.max_vcg_history:
                self.vcg_history.pop(0)

            print(f"‚úÖ VCG completo guardado - Turno {vcg_completo['turno']}")
            print(f"   üìù APEIRON: {len(apeiron_response)} chars")
            print(f"   üß† SOPHIA: {len(sophia_response)} chars")
            print(f"   ‚ö° LOGOS: {len(logos_response)} chars")
            print(f"   üéÆ Board State: Guardado")
            print(f"   üìä Score: {vcg_completo['score']}")
            print(f"   üìö Historia VCG: {len(self.vcg_history)}/{self.max_vcg_history}")

        except Exception as e:
            print(f"‚ö†Ô∏è Error al guardar VCG: {e}")

    def choose_action(
        self, frames: list[FrameData], latest_frame: FrameData
    ) -> GameAction:
        """Choose which action the Agent should take, fill in any arguments, and return it."""

        # Mostrar el estado actual del mapa antes de tomar la decisi√≥n
        self.show_current_map(latest_frame)

        if latest_frame.state in [GameState.NOT_PLAYED, GameState.GAME_OVER]:
            # if game is not started (at init or after GAME_OVER) we need to reset
            # add a small delay before resetting after GAME_OVER to avoid timeout
            action = GameAction.RESET
            action.reasoning = "Reseteando juego por estado inicial o game over"
            print(f"\nüîÑ ACCI√ìN: RESET (autom√°tica)")
            return action

        # PRIORIDAD 1: Verificar si hay √≥rdenes pendientes de LOGOS
        if self.has_pending_orders():
            print(f"\nüìã === EJECUTANDO √ìRDENES PENDIENTES DE LOGOS ===")
            return self._execute_pending_order()

        # PRIORIDAD 2: Si no hay √≥rdenes pendientes, ejecutar flujo cognitivo completo
        # Ejecutar el flujo cognitivo TOMAS (APEIRON ‚Üí SOPHIA ‚Üí LOGOS)
        logos_response, logos_json = self.ask_gemini_analysis(latest_frame)

        # Intentar extraer √≥rdenes (singular o m√∫ltiples) de la respuesta de LOGOS
        action = None
        if logos_json and "command_phase" in logos_json:
            command_phase = logos_json["command_phase"]

            # OPCI√ìN 1: Verificar si LOGOS devolvi√≥ m√∫ltiples √≥rdenes secuenciales
            if (
                "sequential_orders" in command_phase
                and command_phase["sequential_orders"]
            ):
                ordenes_lista = command_phase["sequential_orders"]
                reasoning = command_phase.get(
                    "chosen_plan_reasoning", "Secuencia de √≥rdenes de LOGOS"
                )

                if isinstance(ordenes_lista, list) and len(ordenes_lista) > 0:
                    # LOGOS devolvi√≥ m√∫ltiples √≥rdenes - guardarlas para ejecuci√≥n secuencial
                    self.add_orders_from_logos(ordenes_lista, reasoning)

                    # Ejecutar la primera orden inmediatamente
                    return self._execute_pending_order()

            # OPCI√ìN 2: Orden √∫nica (comportamiento original)
            immediate_command = command_phase.get("immediate_command", {})

            if "action" in immediate_command:
                action_command = immediate_command["action"]

                # Mapear comandos de texto a n√∫meros de acci√≥n
                action_map = {
                    "move_up": 1,
                    "move_down": 2,
                    "move_left": 3,
                    "move_right": 4,
                    "space": 5,
                    "click": 6,
                }

                suggested_action_number = action_map.get(action_command.lower())

                if suggested_action_number:
                    action = self._map_action_number_to_game_action(
                        suggested_action_number
                    )

                    # Configurar reasoning con toda la informaci√≥n de LOGOS
                    action.reasoning = {
                        "tomas_flow": "APEIRON ‚Üí SOPHIA ‚Üí LOGOS",
                        "execution_mode": "ORDEN_UNICA_LOGOS",
                        "objetivo_turno": logos_json.get("intent_phase", {}).get(
                            "plan_objective", ""
                        ),
                        "decision_final": logos_json.get("choice_phase", {}).get(
                            "final_decision", {}
                        ),
                        "comando_inmediato": immediate_command,
                        "resultado_esperado": logos_json.get(
                            "predictive_judgment_phase", {}
                        ).get("expected_outcome", ""),
                        "suggested_action": suggested_action_number,
                    }

                    print(
                        f"\n‚ö° ACCI√ìN √öNICA DECIDIDA POR LOGOS: {action_command} -> {action.value}"
                    )
                    print(f"üéØ Objetivo: {action.reasoning['objetivo_turno']}")
                    print(
                        f"üîÆ Resultado esperado: {action.reasoning['resultado_esperado']}"
                    )

        # Fallback si no se pudo extraer acci√≥n v√°lida de LOGOS
        if not action:
            print(
                "‚ö†Ô∏è No se pudo extraer acci√≥n v√°lida de LOGOS, usando acci√≥n aleatoria"
            )
            action = random.choice([a for a in GameAction if a is not GameAction.RESET])
            action.reasoning = {
                "fallback_reason": "Error al extraer acci√≥n de LOGOS",
                "random_choice": f"Acci√≥n aleatoria: {action.value}",
                "logos_response_available": logos_json is not None,
            }
            print(f"\nüé≤ ACCI√ìN FALLBACK: {action.value} (aleatoria)")

        if action.is_complex():
            action.set_data(
                {
                    "x": random.randint(0, 63),
                    "y": random.randint(0, 63),
                }
            )

        # Guardar informaci√≥n para la memoria epis√≥dica
        self._last_frame_before_action = latest_frame
        self._last_action = action
        self._last_gemini_analysis = logos_json

        # Guardar informaci√≥n de acci√≥n para el pr√≥ximo an√°lisis espacial
        self.previous_action = (
            action.value
            if hasattr(action, "value") and isinstance(action.value, int)
            else None
        )

        # Extraer coordenadas si es una acci√≥n compleja
        if action.is_complex() and hasattr(action, "data") and action.data:
            self.previous_action_coordinates = (
                action.data.get("x"),
                action.data.get("y"),
            )
        else:
            self.previous_action_coordinates = None

        print(f"\n‚úÖ DECISI√ìN FINAL: {action.value}")
        return action

    def append_frame(self, frame: FrameData) -> None:
        """Override para capturar cambios y actualizar memoria epis√≥dica"""
        super().append_frame(frame)

        # Si tenemos informaci√≥n de la acci√≥n anterior, actualizar memoria
        if hasattr(self, "_last_frame_before_action") and hasattr(self, "_last_action"):
            self.add_to_episodic_memory(
                action=self._last_action,
                frame_before=self._last_frame_before_action,
                frame_after=frame,
                gemini_analysis=getattr(self, "_last_gemini_analysis", None),
            )

            # Limpiar variables temporales
            delattr(self, "_last_frame_before_action")
            delattr(self, "_last_action")
            if hasattr(self, "_last_gemini_analysis"):
                delattr(self, "_last_gemini_analysis")
