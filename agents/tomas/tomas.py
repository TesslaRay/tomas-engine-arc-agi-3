import json
import os
import random
import re
import time
import base64
from typing import Any, Dict, List, Optional

from ..agent import Agent
from ..structs import FrameData, GameAction, GameState

# utils
from ..image_utils import grid_to_image

# services
from ..services.gemini_service import GeminiService
from ..services.cerebras_service import CerebrasService

# modules
from ..tomas_engine.spatial_perception_module import SpatialPerceptionModule
from ..tomas_engine.constants import get_action_name


class Tomas(Agent):
    """Tomas agent"""

    MAX_ACTIONS = 20

    def __init__(self, *args: Any, llm_provider: str = "gemini", **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)

        print(f"ðŸ§  Starting Tomas")

        # Initialize Gemini service
        try:
            self.gemini_service = GeminiService()
            print("âœ… Gemini service initialized")

            self.cerebras = CerebrasService()
            print("âœ… Cerebras service initialized")
        except Exception as e:
            print(f"âš ï¸ Error initializing Gemini: {e}")
            self.gemini_service = None

        # Initialize spatial perception module
        try:
            self.spatial_perception = SpatialPerceptionModule(provider=llm_provider)
            print(f"âœ… Perception module initialized with {llm_provider.upper()}")
        except Exception as e:
            print(f"âš ï¸ Error initializing spatial perception: {e}")
            self.spatial_perception = None

        # Initialize episodic memory
        self.episodic_memory: List[Dict[str, Any]] = []
        self.max_memory_size = 10  # Keep last 10 moves

        # Store last 3 images for analysis
        self.recent_images: List[Any] = []  # PIL Images
        self.max_images = 3

        # Global vector cognition memory
        self.vcg_history: List[Dict[str, Any]] = []
        self.max_vcg_history = 5  # Keep last 5 VCGs

        # Previous board state for differential analysis
        # Initialize with dummy matrix "closed eyes" (64x64 of zeros)
        self.previous_board_state = self._create_dummy_closed_eyes_matrix()
        self.previous_frame_data = None

        # Previous action information for spatial analysis
        self.previous_action = None
        self.previous_action_coordinates = None

        # LOGOS orders queue
        self.pending_orders = []  # Pending orders
        self.current_order_index = 0  # Current order index
        self.orders_reasoning = ""  # Reasoning for the sequence of orders

        print(
            f"ðŸ‘ï¸ Closed eyes matrix initialized: {len(self.previous_board_state)}x{len(self.previous_board_state[0])} (all black)"
        )
        print(f"ðŸ“‹ LOGOS orders queue initialized: 0 pending orders")

    def _create_dummy_closed_eyes_matrix(self) -> List[List[int]]:
        """
        Create dummy matrix that represents "closed eyes"

        This matrix is used as the initial "previous" state for the spatial analysis
        to work from the first turn of the game.

        Returns:
            Matrix 64x64 filled with 16 (pink)
        """
        return [[16 for _ in range(64)] for _ in range(64)]

    def add_orders_from_logos(
        self, orders_list: List[Dict[str, Any]], reasoning: str = ""
    ) -> None:
        """
        Agregar una secuencia de Ã³rdenes de LOGOS para ejecutar

        Args:
            orders_list: Lista de Ã³rdenes con formato [{"action": "move_up", "coordinates": (x, y)}, ...]
            reasoning: Razonamiento detrÃ¡s de la secuencia de Ã³rdenes
        """
        self.pending_orders = orders_list.copy()
        self.current_order_index = 0
        self.orders_reasoning = reasoning

        print(f"\nðŸ“‹ === LOGOS HA EMITIDO {len(orders_list)} Ã“RDENES ===")
        for i, order in enumerate(orders_list, 1):
            action_name = order.get("action", "unknown")
            coords = order.get("coordinates")
            coord_info = f" en {coords}" if coords else ""
            print(f"   {i}. {action_name}{coord_info}")
        print(f"ðŸŽ¯ Razonamiento: {reasoning}")
        print("=" * 50)

    def has_pending_orders(self) -> bool:
        """
        Verificar si hay Ã³rdenes pendientes por ejecutar

        Returns:
            True si hay Ã³rdenes pendientes, False si no
        """
        return self.pending_orders and self.current_order_index < len(
            self.pending_orders
        )

    def get_next_order(self) -> Optional[Dict[str, Any]]:
        """
        Obtener la siguiente orden a ejecutar

        Returns:
            Diccionario con la orden o None si no hay mÃ¡s Ã³rdenes
        """
        if self.has_pending_orders():
            current_order = self.pending_orders[self.current_order_index]
            self.current_order_index += 1

            print(
                f"\nâš¡ EJECUTANDO ORDEN {self.current_order_index}/{len(self.pending_orders)}"
            )
            print(f"   ðŸŽ¯ AcciÃ³n: {current_order.get('action', 'unknown')}")
            if "coordinates" in current_order:
                print(f"   ðŸ“ Coordenadas: {current_order['coordinates']}")
            print(
                f"   ðŸ“‹ Ã“rdenes restantes: {len(self.pending_orders) - self.current_order_index}"
            )

            return current_order
        return None

    def clear_orders(self) -> None:
        """
        Limpiar todas las Ã³rdenes pendientes
        """
        orders_completed = self.current_order_index
        total_orders = len(self.pending_orders)

        self.pending_orders = []
        self.current_order_index = 0
        self.orders_reasoning = ""

        print(f"\nâœ… === SECUENCIA DE Ã“RDENES COMPLETADA ===")
        print(f"ðŸ“Š Ã“rdenes ejecutadas: {orders_completed}/{total_orders}")
        print(
            f"ðŸ”„ Regresando al flujo cognitivo completo: Spatial Perception â†’ APEIRON â†’ SOPHIA â†’ LOGOS"
        )
        print("=" * 50)

    def _execute_pending_order(self) -> GameAction:
        """
        Ejecutar la siguiente orden pendiente de LOGOS

        Returns:
            GameAction correspondiente a la orden pendiente
        """
        next_order = self.get_next_order()

        if not next_order:
            # No hay mÃ¡s Ã³rdenes vÃ¡lidas, esto no deberÃ­a pasar
            print(
                "âŒ Error: se llamÃ³ _execute_pending_order pero no hay Ã³rdenes vÃ¡lidas"
            )
            self.clear_orders()
            # En lugar de aleatorio, fallback que nunca deberÃ­a ejecutarse
            action = GameAction.ACTION1  # Solo como fallback de emergencia
            action.reasoning = (
                "Error interno: orden invÃ¡lida, requiere revisiÃ³n del cÃ³digo"
            )
            return action

        # Mapear la orden a GameAction
        action_command = next_order.get("action", "").lower()
        action_map = {
            "move_up": 1,
            "move_down": 2,
            "move_left": 3,
            "move_right": 4,
            "space": 5,
            "click": 6,
        }

        suggested_action_number = action_map.get(action_command)

        if suggested_action_number:
            action = self._map_action_number_to_game_action(suggested_action_number)

            # Configurar reasoning con informaciÃ³n de la secuencia
            remaining_orders = len(self.pending_orders) - self.current_order_index
            action.reasoning = {
                "execution_mode": "ORDEN_SECUENCIAL_LOGOS",
                "orden_actual": f"{self.current_order_index}/{len(self.pending_orders)}",
                "accion_ejecutada": action_command,
                "ordenes_restantes": remaining_orders,
                "razonamiento_secuencia": self.orders_reasoning,
                "coordinates": next_order.get("coordinates"),
            }

            # Configurar coordenadas si es una acciÃ³n compleja
            if action.is_complex() and "coordinates" in next_order:
                coords = next_order["coordinates"]
                if isinstance(coords, (list, tuple)) and len(coords) >= 2:
                    action.set_data({"x": coords[0], "y": coords[1]})
                else:
                    # Fallback a coordenadas aleatorias si las coordenadas no son vÃ¡lidas
                    action.set_data(
                        {"x": random.randint(0, 63), "y": random.randint(0, 63)}
                    )

            # Si esta es la Ãºltima orden, informar sobre el prÃ³ximo flujo
            if not self.has_pending_orders():
                print(f"\nðŸ Esta fue la ÃšLTIMA orden de la secuencia")
                print(
                    f"ðŸ”„ En el prÃ³ximo turno: Spatial Perception analizarÃ¡ TODOS los cambios acumulados"
                )
                print(
                    f"   â†’ APEIRON verÃ¡ la historia completa de las Ã³rdenes ejecutadas"
                )

            print(
                f"\nâš¡ EJECUTANDO: {action_command} (orden {self.current_order_index}/{len(self.pending_orders)})"
            )
            return action
        else:
            # AcciÃ³n no reconocida
            print(f"âŒ AcciÃ³n no reconocida en orden: '{action_command}'")
            print(f"ðŸ”„ Limpiando cola de Ã³rdenes y regresando al flujo completo")
            self.clear_orders()
            # En lugar de aleatorio, forzar el flujo completo en el siguiente choose_action
            action = GameAction.ACTION1  # Fallback temporal
            action.reasoning = f"Error: acciÃ³n no reconocida '{action_command}', regresando al flujo completo"
            return action

    def load_markdown_file(self, file_path: str) -> str:
        """
        Cargar un archivo markdown de forma genÃ©rica

        Args:
            file_path: Ruta relativa al archivo .md desde el directorio tomas/

        Returns:
            Contenido del archivo como string
        """
        try:
            # Obtener la ruta del directorio actual del archivo
            current_dir = os.path.dirname(os.path.abspath(__file__))
            full_path = os.path.join(current_dir, file_path)

            if not os.path.exists(full_path):
                print(f"âš ï¸ Archivo {file_path} no encontrado en: {full_path}")
                return f"# Error: Archivo {file_path} no encontrado"

            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read()

            print(f"âœ… Archivo {file_path} cargado correctamente")
            return content

        except Exception as e:
            print(f"âš ï¸ Error al cargar {file_path}: {e}")
            return f"# Error: No se pudo cargar {file_path}"

    def analyze_spatial_perception(self, current_frame: FrameData) -> Optional[str]:
        """
        Realizar anÃ¡lisis de percepciÃ³n espacial comparando el estado actual con el anterior

        Args:
            current_frame: Estado actual del juego

        Returns:
            AnÃ¡lisis espacial como string o None si no hay anÃ¡lisis disponible
        """
        if not self.spatial_perception or current_frame.is_empty():
            return None

        # NOTA: Ya no verificamos self.previous_board_state porque siempre tenemos la matriz dummy

        try:
            print(f"\nðŸŽ¨ === INICIANDO ANÃLISIS DE PERCEPCIÃ“N ESPACIAL ===")

            # Determinar si es el primer turno (comparando con matriz dummy)
            is_first_turn = all(
                all(cell == 0 for cell in row) for row in self.previous_board_state
            )

            if is_first_turn:
                print(
                    f"ðŸ‘ï¸ PRIMER TURNO: Comparando matriz actual vs 'ojos cerrados' (dummy)"
                )
            else:
                print(f"ðŸ”„ TURNO SUBSECUENTE: Comparando estado actual vs anterior")

            # Realizar anÃ¡lisis de efectos de la acciÃ³n anterior
            analysis_result = self.spatial_perception.analyze_action_effect(
                matrix_before=self.previous_board_state,
                matrix_after=current_frame.frame,
                action=self.previous_action if self.previous_action else 0,
                coordinates=self.previous_action_coordinates,
                include_visual_interpretation=True,  # Incluir anÃ¡lisis visual de Gemini
            )

            print(f"âœ… AnÃ¡lisis espacial completado")
            print(f"ðŸ“Š Resultado: {len(analysis_result)} caracteres")
            print(f"ðŸ” AnÃ¡lisis detallado:")
            print("=" * 50)
            print(analysis_result)
            print("=" * 50)

            return analysis_result

        except Exception as e:
            print(f"âŒ Error en anÃ¡lisis de percepciÃ³n espacial: {e}")
            return None

    def ask_apeiron_analysis(
        self,
        latest_frame: FrameData,
        vector_cognitivo_global_anterior: Optional[str] = None,
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Consultar a APEIRON (LLM1) para anÃ¡lisis perceptual

        Args:
            latest_frame: Estado actual del frame
            vector_cognitivo_global_anterior: VCG del turno anterior (opcional)

        Returns:
            Tupla con (respuesta_completa, json_extraido)
        """
        if not self.gemini_service or latest_frame.is_empty():
            return "AnÃ¡lisis no disponible", None

        try:
            # Cargar los archivos necesarios
            alma_content = self.load_markdown_file("alma.md")
            apeiron_system_prompt = self.load_markdown_file(
                "processus/apeiron/system-prompt.md"
            )
            apeiron_response_format = self.load_markdown_file(
                "processus/apeiron/response.md"
            )

            # Realizar anÃ¡lisis de percepciÃ³n espacial si hay estado anterior
            spatial_analysis = self.analyze_spatial_perception(latest_frame)

            # Determinar si es el primer turno para contexto adicional
            is_first_turn = all(
                all(cell == 0 for cell in row) for row in self.previous_board_state
            )
            first_turn_context = ""
            if is_first_turn:
                first_turn_context = """
## CONTEXTO ESPECIAL - PRIMER TURNO:
Este es el primer turno del juego. El anÃ¡lisis de percepciÃ³n espacial compara el estado actual del tablero contra una matriz "ojos cerrados" (todo en negro/ceros). Esto significa que TODAS las figuras/objetos visibles en el tablero actual son NUEVAS APARICIONES desde el estado inicial de "ojos cerrados".

El anÃ¡lisis espacial detectarÃ¡ todos los elementos del tablero como "apariciones" o "materializaciones" desde el estado de oscuridad total.
"""

            # Construir el prompt combinado
            combined_prompt = f"""
{alma_content}

{apeiron_system_prompt}

{apeiron_response_format}

## ESTADO ACTUAL DEL JUEGO:
- PuntuaciÃ³n: {latest_frame.score}
- AcciÃ³n nÃºmero: {self.action_counter}
- Estado del juego: {latest_frame.state}

{first_turn_context}

## input_fresco (board_state actual):
{latest_frame.frame}

## board_state_anterior (para anÃ¡lisis diferencial):
{self.previous_board_state if self.previous_board_state is not None else "Este es el primer turno - no hay estado anterior"}

## vector_cognitivo_global_anterior:
{vector_cognitivo_global_anterior if vector_cognitivo_global_anterior else "Este es el primer turno - no hay VCG anterior"}

## analisis_percepcion_espacial:
{spatial_analysis if spatial_analysis else "No hay anÃ¡lisis espacial disponible - primer turno o sin cambios"}

IMPORTANTE: Tu respuesta DEBE ser un JSON vÃ¡lido que incluya el campo "timestamp" en formato ISO 8601 (ejemplo: "2025-08-05T10:30:00.000Z"). Genera el timestamp actual automÃ¡ticamente.
"""

            print(f"\nðŸ§  === CONSULTANDO APEIRON (LLM1) ===")
            print(f"ðŸŽ¯ Fase: AnÃ¡lisis Perceptual")

            # Log de entrada
            print(f"\nðŸ“¥ ENTRADA APEIRON:")
            print(f"   ðŸ“„ Alma: {len(alma_content)} chars")
            print(f"   ðŸ“„ System Prompt: {len(apeiron_system_prompt)} chars")
            print(f"   ðŸ“„ Response Format: {len(apeiron_response_format)} chars")
            print(
                f"   ðŸŽ® Frame Data: {latest_frame.frame.shape if hasattr(latest_frame.frame, 'shape') else 'N/A'}"
            )
            print(
                f"   ðŸ“Š VCG Anterior: {len(vector_cognitivo_global_anterior) if vector_cognitivo_global_anterior else 0} chars"
            )
            print(
                f"   ðŸŽ¨ PercepciÃ³n Espacial: {len(spatial_analysis) if spatial_analysis else 0} chars"
            )
            print(f"   ðŸ“ Prompt Total: {len(combined_prompt)} chars")

            response = self.gemini_service.generate_with_images_sync(
                prompt=combined_prompt,
                images=[],  # Sin imÃ¡genes por ahora, solo matriz
                system_prompt=alma_content,
            )

            # Log de salida
            print(f"\nðŸ“¤ SALIDA APEIRON:")
            print(f"   âœ… Completado en {response.duration_ms}ms")
            print(f"   ðŸŽ« Tokens: {response.usage['total_tokens']}")
            print(f"   ðŸ“ Respuesta: {len(response.content)} chars")
            print(f"   ðŸ“„ Contenido completo:")
            print(f"{response.content}")

            # Extraer JSON de la respuesta
            extracted_json = self.extract_json_from_llm_response(
                response.content, "apeiron"
            )

            return response.content, extracted_json

        except Exception as e:
            print(f"âŒ Error en APEIRON: {e}")
            return f"Error en APEIRON: {str(e)}", None

    def ask_sophia_analysis(
        self, apeiron_response: str
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Consultar a SOPHIA (LLM2) para anÃ¡lisis epistÃ©mico

        Args:
            apeiron_response: Respuesta completa de APEIRON del turno actual

        Returns:
            Tupla con (respuesta_completa, json_extraido)
        """
        if not self.gemini_service:
            return "AnÃ¡lisis no disponible", None

        try:
            # Cargar los archivos necesarios
            alma_content = self.load_markdown_file("alma.md")
            sophia_system_prompt = self.load_markdown_file(
                "processus/sophia/system-prompt.md"
            )
            sophia_response_format = self.load_markdown_file(
                "processus/sophia/response.md"
            )

            # Construir el prompt combinado
            combined_prompt = f"""
{alma_content}

{sophia_system_prompt}

{sophia_response_format}

## Vector Cognitivo Global actualizado por APEIRON:
{apeiron_response}

IMPORTANTE: Tu respuesta DEBE ser un JSON vÃ¡lido que incluya el campo "timestamp" en formato ISO 8601 (ejemplo: "2025-08-05T10:30:00.000Z"). Genera el timestamp actual automÃ¡ticamente.
"""

            print(f"\nðŸ§  === CONSULTANDO SOPHIA (LLM2) ===")
            print(f"ðŸŽ¯ Fase: AnÃ¡lisis EpistÃ©mico")

            # Log de entrada
            print(f"\nðŸ“¥ ENTRADA SOPHIA:")
            print(f"   ðŸ“„ Alma: {len(alma_content)} chars")
            print(f"   ðŸ“„ System Prompt: {len(sophia_system_prompt)} chars")
            print(f"   ðŸ“„ Response Format: {len(sophia_response_format)} chars")
            print(f"   ðŸ§  Respuesta APEIRON: {len(apeiron_response)} chars")
            print(f"   ðŸ“ Prompt Total: {len(combined_prompt)} chars")

            # response = self.gemini_service.generate_with_images_sync(
            #     prompt=combined_prompt,
            #     images=[],  # Sophia no necesita imÃ¡genes, trabaja con conceptos
            #     system_prompt=alma_content,
            # )
            response = self.cerebras.generate_text_sync(
                prompt=combined_prompt,
                system_prompt=alma_content,
            )

            # Log de salida
            print(f"\nðŸ“¤ SALIDA SOPHIA:")
            print(f"   âœ… Completado en {response.duration_ms}ms")
            print(f"   ðŸŽ« Tokens: {response.usage['total_tokens']}")
            print(f"   ðŸ“ Respuesta: {len(response.content)} chars")
            print(f"   ðŸ“„ Contenido completo:")
            print(f"{response.content}")

            # Extraer JSON de la respuesta
            extracted_json = self.extract_json_from_llm_response(
                response.content, "sophia"
            )

            return response.content, extracted_json

        except Exception as e:
            print(f"âŒ Error en SOPHIA: {e}")
            return f"Error en SOPHIA: {str(e)}", None

    def ask_logos_analysis(
        self, sophia_response: str
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Consultar a LOGOS (LLM3) para deliberaciÃ³n y acciÃ³n

        Args:
            sophia_response: Respuesta completa de SOPHIA del turno actual

        Returns:
            Tupla con (respuesta_completa, json_extraido)
        """
        if not self.gemini_service:
            return "AnÃ¡lisis no disponible", None

        try:
            # Cargar los archivos necesarios
            alma_content = self.load_markdown_file("alma.md")
            logos_system_prompt = self.load_markdown_file(
                "processus/logos/system-prompt.md"
            )
            logos_response_format = self.load_markdown_file(
                "processus/logos/response.md"
            )

            # Construir el prompt combinado
            combined_prompt = f"""
{alma_content}

{logos_system_prompt}

{logos_response_format}

## Vector Cognitivo Global enriquecido por SOPHIA:
{sophia_response}

IMPORTANTE: Tu respuesta DEBE ser un JSON vÃ¡lido que incluya el campo "timestamp" en formato ISO 8601 (ejemplo: "2025-08-05T10:30:00.000Z"). Genera el timestamp actual automÃ¡ticamente.
"""

            print(f"\nðŸ§  === CONSULTANDO LOGOS (LLM3) ===")
            print(f"ðŸŽ¯ Fase: DeliberaciÃ³n y AcciÃ³n")

            # Log de entrada
            print(f"\nðŸ“¥ ENTRADA LOGOS:")
            print(f"   ðŸ“„ Alma: {len(alma_content)} chars")
            print(f"   ðŸ“„ System Prompt: {len(logos_system_prompt)} chars")
            print(f"   ðŸ“„ Response Format: {len(logos_response_format)} chars")
            print(f"   ðŸ§  Respuesta SOPHIA: {len(sophia_response)} chars")
            print(f"   ðŸ“ Prompt Total: {len(combined_prompt)} chars")

            # response = self.gemini_service.generate_with_images_sync(
            #     prompt=combined_prompt,
            #     images=[],  # Logos no necesita imÃ¡genes, trabaja con estrategia
            #     system_prompt=alma_content,
            # )
            response = self.cerebras.generate_text_sync(
                prompt=combined_prompt,
                system_prompt=alma_content,
            )

            # Log de salida
            print(f"\nðŸ“¤ SALIDA LOGOS:")
            print(f"   âœ… Completado en {response.duration_ms}ms")
            print(f"   ðŸŽ« Tokens: {response.usage['total_tokens']}")
            print(f"   ðŸ“ Respuesta: {len(response.content)} chars")
            print(f"   ðŸ“„ Contenido completo:")
            print(f"{response.content}")

            # Extraer JSON de la respuesta
            extracted_json = self.extract_json_from_llm_response(
                response.content, "logos"
            )

            return response.content, extracted_json

        except Exception as e:
            print(f"âŒ Error en LOGOS: {e}")
            return f"Error en LOGOS: {str(e)}", None

    def extract_json_from_llm_response(
        self, llm_response: str, llm_type: str
    ) -> Optional[Dict[str, Any]]:
        """
        Extrae el JSON de la respuesta del LLM segÃºn el tipo (apeiron, sophia, logos)

        Args:
            llm_response: Respuesta completa del LLM
            llm_type: Tipo de LLM ("apeiron", "sophia", "logos")

        Returns:
            Diccionario con el JSON extraÃ­do o None si no se encuentra
        """
        try:
            # Buscar el JSON principal usando un enfoque mÃ¡s preciso
            # Primero intentar encontrar bloques JSON con llaves balanceadas
            json_start = llm_response.find("{")
            if json_start == -1:
                print(f"âŒ No se encontrÃ³ JSON en la respuesta de {llm_type.upper()}")
                return None

            # Buscar el JSON completo balanceando llaves
            brace_count = 0
            json_end = json_start
            for i, char in enumerate(llm_response[json_start:], json_start):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break

            if brace_count != 0:
                print(
                    f"âŒ JSON mal formateado en {llm_type.upper()} - llaves no balanceadas"
                )
                return None

            # Extraer el JSON completo
            json_text = llm_response[json_start:json_end]

            try:
                parsed_json = json.loads(json_text)

                # Definir campos requeridos segÃºn el tipo de LLM
                required_fields = {
                    "apeiron": [
                        "timestamp",
                        "causal_narrative_of_turn",
                        "conceptualized_entities",
                        "new_turn_learnings",
                        "synthesis_for_next_cycle",
                    ],
                    "sophia": [
                        "timestamp",
                        "epistemic_analysis",
                        "archetype_analysis",
                        "verified_game_rules",
                        "global_game_theories",
                    ],
                    "logos": [
                        "timestamp",
                        "intent_phase",
                        "counsel_phase",
                        "choice_phase",
                        "command_phase",
                        "predictive_judgment_phase",
                    ],
                }

                target_fields = required_fields.get(llm_type, [])

                # Validar que tenga los campos requeridos segÃºn el tipo
                if all(field in parsed_json for field in target_fields):
                    print(f"âœ… JSON vÃ¡lido extraÃ­do de {llm_type.upper()}")
                    return parsed_json
                else:
                    print(
                        f"âš ï¸ JSON de {llm_type.upper()} no tiene todos los campos requeridos"
                    )
                    print(f"   Esperados: {target_fields}")
                    print(f"   Encontrados: {list(parsed_json.keys())}")
                    return None

            except json.JSONDecodeError as e:
                print(f"âŒ Error al parsear JSON de {llm_type.upper()}: {e}")
                return None

        except Exception as e:
            print(f"âŒ Error al extraer JSON de {llm_type.upper()}: {e}")
            return None

    def llmJsonExtractor(self, llm_response: str) -> Optional[Dict[str, Any]]:
        """
        MÃ©todo legacy - mantener para compatibilidad
        """
        return self.extract_json_from_llm_response(llm_response, "logos")

    def _map_action_number_to_game_action(self, action_number: int) -> GameAction:
        """
        Mapear nÃºmero de acciÃ³n del JSON a GameAction

        Args:
            action_number: NÃºmero de acciÃ³n (1-6)

        Returns:
            GameAction correspondiente
        """
        action_map = {
            1: GameAction.ACTION1,  # Arriba
            2: GameAction.ACTION2,  # Abajo
            3: GameAction.ACTION3,  # Izquierda
            4: GameAction.ACTION4,  # Derecha
            5: GameAction.ACTION5,  # Barra espaciadora
            6: GameAction.ACTION6,  # Click del mouse
        }

        return action_map.get(
            action_number, GameAction.ACTION1
        )  # Default a ACTION1 si no se encuentra

    def add_to_episodic_memory(
        self,
        action: GameAction,
        frame_before: FrameData,
        frame_after: FrameData,
        gemini_analysis: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        Agregar un movimiento a la memoria episÃ³dica

        Args:
            action: AcciÃ³n tomada
            frame_before: Estado del juego antes de la acciÃ³n
            frame_after: Estado del juego despuÃ©s de la acciÃ³n
            gemini_analysis: AnÃ¡lisis de Gemini para esta acciÃ³n
        """
        memory_entry = {
            "action_number": self.action_counter,
            "action": action.value,
            "action_name": self._get_action_name(action.value),
            "score_before": frame_before.score,
            "score_after": frame_after.score,
            "score_change": frame_after.score - frame_before.score,
            "game_state_before": frame_before.state.value,
            "game_state_after": frame_after.state.value,
            "gemini_reasoning": (
                gemini_analysis.get("current_hypothesis", "") if gemini_analysis else ""
            ),
            "timestamp": time.time(),
        }

        # Agregar a la memoria
        self.episodic_memory.append(memory_entry)

        # Mantener solo los Ãºltimos N movimientos
        if len(self.episodic_memory) > self.max_memory_size:
            self.episodic_memory.pop(0)

        print(f"ðŸ“ Memoria actualizada: {len(self.episodic_memory)} entradas")

    def _get_action_name(self, action_value: int) -> str:
        """Convertir nÃºmero de acciÃ³n a nombre legible"""
        # Usar las constantes centralizadas pero con nombres en espaÃ±ol
        spanish_names = {
            0: "RESET",
            1: "Arriba",
            2: "Abajo",
            3: "Izquierda",
            4: "Derecha",
            5: "Barra",
            6: "Click",
        }
        return spanish_names.get(action_value, f"AcciÃ³n {action_value}")

    def get_memory_summary(self) -> str:
        """
        Generar un resumen de la memoria episÃ³dica para el prompt de Gemini

        Returns:
            String con resumen de movimientos recientes
        """
        if not self.episodic_memory:
            return (
                "## Historial de Movimientos\nEste es el primer movimiento del juego."
            )

        summary = "## Historial de Movimientos Recientes\n\n"

        for i, entry in enumerate(
            self.episodic_memory[-5:], 1
        ):  # Ãšltimos 5 movimientos
            score_indicator = ""
            if entry["score_change"] > 0:
                score_indicator = f" (+{entry['score_change']} puntos âœ…)"
            elif entry["score_change"] < 0:
                score_indicator = f" ({entry['score_change']} puntos âŒ)"
            else:
                score_indicator = " (sin cambio de puntuaciÃ³n)"

            summary += f"**Movimiento {entry['action_number']}:** {entry['action_name']}{score_indicator}\n"
            if entry["gemini_reasoning"]:
                summary += f"- Razonamiento: {entry['gemini_reasoning']}\n"
            summary += f"- Estado: {entry['game_state_before']} â†’ {entry['game_state_after']}\n\n"

        # Agregar anÃ¡lisis de patrones
        if len(self.episodic_memory) >= 3:
            recent_scores = [
                entry["score_change"] for entry in self.episodic_memory[-3:]
            ]
            if all(s >= 0 for s in recent_scores):
                summary += "ðŸŽ¯ **PatrÃ³n observado:** Los Ãºltimos movimientos han sido exitosos o neutrales.\n"
            elif all(s <= 0 for s in recent_scores):
                summary += "âš ï¸ **PatrÃ³n observado:** Los Ãºltimos movimientos no han mejorado la puntuaciÃ³n.\n"

        return summary

    def add_image_to_history(self, image) -> None:
        """
        Agregar imagen al historial de imÃ¡genes recientes

        Args:
            image: PIL Image object
        """
        self.recent_images.append(image)

        # Mantener solo las Ãºltimas 3 imÃ¡genes
        if len(self.recent_images) > self.max_images:
            self.recent_images.pop(0)

        print(
            f"ðŸ“¸ Historial de imÃ¡genes actualizado: {len(self.recent_images)} imÃ¡genes"
        )

    def display_image_in_iterm2(self, image) -> None:
        """
        Mostrar imagen directamente en iTerm2 usando secuencias de escape

        Args:
            image: PIL Image object (ya viene escalada 5x desde grid_to_image)
        """
        try:
            import io

            # Convertir imagen a bytes
            img_buffer = io.BytesIO()
            image.save(img_buffer, format="PNG")
            img_data = img_buffer.getvalue()

            # Codificar en base64
            img_base64 = base64.b64encode(img_data).decode("utf-8")

            # Secuencia de escape de iTerm2 para mostrar imagen
            print(f"\033]1337;File=inline=1:{img_base64}\a")

        except Exception as e:
            print(f"âš ï¸ Error al mostrar imagen en iTerm2: {e}")

    def display_recent_images_in_iterm2(self) -> None:
        """
        Mostrar las imÃ¡genes recientes disponibles en iTerm2
        """
        if not self.recent_images:
            print("ðŸ“¸ No hay imÃ¡genes en el historial")
            return

        print(f"ðŸ–¼ï¸ === MAPAS RECIENTES ({len(self.recent_images)} imÃ¡genes) ===")

        for i, image in enumerate(self.recent_images):
            if i == len(self.recent_images) - 1:
                print(f"ðŸ“ Mapa actual (turno {self.action_counter}):")
            else:
                print(f"ðŸ“œ Mapa anterior {i+1}:")

            self.display_image_in_iterm2(image)
            print()

        print("=" * 50)

    @property
    def name(self) -> str:
        return f"{super().name}.{self.MAX_ACTIONS}"

    def is_done(self, frames: list[FrameData], latest_frame: FrameData) -> bool:
        """Decide if the agent is done playing or not."""
        return any(
            [
                latest_frame.state is GameState.WIN,
                # uncomment to only let the agent play one time
                # latest_frame.state is GameState.GAME_OVER,
            ]
        )

    def show_current_map(self, latest_frame: FrameData) -> None:
        """Display the current map state as an image and save it."""
        print(f"\n=== ESTADO ACTUAL DEL MAPA ===")
        print(f"Estado del juego: {latest_frame.state}")
        print(f"PuntuaciÃ³n: {latest_frame.score}")
        print(f"AcciÃ³n nÃºmero: {self.action_counter}")

        if latest_frame.is_empty():
            print("Mapa vacÃ­o - no hay datos para mostrar")
            return

        # Convertir el mapa a imagen
        map_image = grid_to_image(latest_frame.frame)

        # Crear directorio images si no existe
        import os

        os.makedirs("images", exist_ok=True)

        # Guardar la imagen con informaciÃ³n del estado
        filename = f"images/tomas_map_action_{self.action_counter:03d}_score_{latest_frame.score:03d}.png"
        map_image.save(filename)

        print(f"Imagen del mapa guardada como: {filename}")
        print(f"Dimensiones de la imagen: {map_image.size}")
        print("=" * 40)

        return map_image

    def ask_gemini_analysis(
        self, latest_frame: FrameData
    ) -> tuple[str, Optional[Dict[str, Any]]]:
        """
        Ejecutar el flujo secuencial APEIRON â†’ SOPHIA â†’ LOGOS

        Returns:
            Tupla con (respuesta_completa_de_logos, json_extraido_de_logos)
        """
        if not self.gemini_service or latest_frame.is_empty():
            return "AnÃ¡lisis no disponible", None

        try:
            # Generar imagen del mapa actual (comentado por ahora)
            # map_image = grid_to_image(latest_frame.frame)

            # Agregar imagen actual al historial (comentado por ahora)
            # self.add_image_to_history(map_image)

            # Mostrar imÃ¡genes recientes en iTerm2 (comentado por ahora)
            # self.display_recent_images_in_iterm2()

            print(f"\nðŸ§  === INICIANDO FLUJO COGNITIVO TOMAS ===")
            print(f"ðŸŽ¯ Turno {self.action_counter} | PuntuaciÃ³n: {latest_frame.score}")
            print(f"ðŸ”„ Flujo: APEIRON â†’ SOPHIA â†’ LOGOS")
            print("=" * 60)

            # Guardar el estado actual como "anterior" para el prÃ³ximo turno
            # (Esto se hace al INICIO del turno, no al final)

            # Obtener VCG anterior si existe
            vector_cognitivo_global_anterior = (
                self.get_vector_cognitivo_global_anterior()
            )

            # Debug: mostrar si tenemos VCG anterior
            if vector_cognitivo_global_anterior:
                print(
                    f"ðŸ“š VCG Anterior disponible: {len(vector_cognitivo_global_anterior)} chars"
                )
            else:
                print(f"ðŸ“š Primer turno - No hay VCG anterior")

            # PASO 1: APEIRON - AnÃ¡lisis Perceptual
            apeiron_response, apeiron_json = self.ask_apeiron_analysis(
                latest_frame, vector_cognitivo_global_anterior
            )

            if not apeiron_json:
                print(
                    "âš ï¸ APEIRON no devolviÃ³ JSON vÃ¡lido, continuando con respuesta textual"
                )

            # PASO 2: SOPHIA - AnÃ¡lisis EpistÃ©mico
            sophia_response, sophia_json = self.ask_sophia_analysis(apeiron_response)

            if not sophia_json:
                print(
                    "âš ï¸ SOPHIA no devolviÃ³ JSON vÃ¡lido, continuando con respuesta textual"
                )

            # PASO 3: LOGOS - DeliberaciÃ³n y AcciÃ³n
            logos_response, logos_json = self.ask_logos_analysis(sophia_response)

            if not logos_json:
                print("âš ï¸ LOGOS no devolviÃ³ JSON vÃ¡lido")

            print(f"\nâœ… === FLUJO COGNITIVO COMPLETADO ===")
            print(f"ðŸ“Š Total de pasos ejecutados: APEIRON âœ… | SOPHIA âœ… | LOGOS âœ…")
            print("=" * 60)

            # Guardar el VCG completo para el prÃ³ximo turno
            # IMPORTANTE: Guardamos el estado ACTUAL como referencia para el PRÃ“XIMO turno
            self.previous_frame_data = latest_frame
            self.previous_board_state = latest_frame.frame
            self.save_vector_cognitivo_global(
                apeiron_response, sophia_response, logos_response
            )

            # Retornar la respuesta de LOGOS (que contiene la decisiÃ³n de acciÃ³n)
            return logos_response, logos_json

        except Exception as e:
            print(f"âŒ Error en flujo TOMAS: {e}")
            return f"Error en flujo TOMAS: {str(e)}", None

    def get_vector_cognitivo_global_anterior(self) -> Optional[str]:
        """
        Obtener el Vector Cognitivo Global completo del turno anterior
        """
        if not self.vcg_history:
            return None

        # Obtener el VCG mÃ¡s reciente
        last_vcg = self.vcg_history[-1]

        # Construir el VCG anterior con toda la informaciÃ³n
        vcg_anterior = f"""
## Vector Cognitivo Global del Turno Anterior (Turno {last_vcg['turno']})

### Estado LLM1 (APEIRON - PercepciÃ³n anterior):
{last_vcg['apeiron_response']}

### Estado LLM2 (SOPHIA - AbstracciÃ³n anterior):
{last_vcg['sophia_response']}

### Estado LLM3 (LOGOS - DeliberaciÃ³n anterior):
{last_vcg['logos_response']}

### board_state anterior:
{last_vcg['board_state']}

### Contexto del turno:
- PuntuaciÃ³n: {last_vcg['score']}
- Estado del juego: {last_vcg['game_state']}
- Timestamp: {last_vcg['timestamp']}
"""
        return vcg_anterior

    def save_vector_cognitivo_global(
        self, apeiron_response: str, sophia_response: str, logos_response: str
    ) -> None:
        """
        Guardar el Vector Cognitivo Global completo del turno actual con toda la informaciÃ³n
        """
        try:
            print(f"\nðŸ’¾ === GUARDANDO VCG TURNO {self.action_counter} ===")

            # Crear VCG completo con toda la informaciÃ³n necesaria
            vcg_completo = {
                "turno": self.action_counter,
                "timestamp": time.time(),
                "apeiron_response": apeiron_response,
                "sophia_response": sophia_response,
                "logos_response": logos_response,
                "board_state": (
                    str(self.previous_frame_data.frame)
                    if self.previous_frame_data
                    else "N/A"
                ),
                "score": (
                    self.previous_frame_data.score if self.previous_frame_data else 0
                ),
                "game_state": (
                    str(self.previous_frame_data.state)
                    if self.previous_frame_data
                    else "UNKNOWN"
                ),
            }

            # Agregar a la historia de VCG
            self.vcg_history.append(vcg_completo)

            # Mantener solo los Ãºltimos N VCG
            if len(self.vcg_history) > self.max_vcg_history:
                self.vcg_history.pop(0)

            print(f"âœ… VCG completo guardado - Turno {vcg_completo['turno']}")
            print(f"   ðŸ“ APEIRON: {len(apeiron_response)} chars")
            print(f"   ðŸ§  SOPHIA: {len(sophia_response)} chars")
            print(f"   âš¡ LOGOS: {len(logos_response)} chars")
            print(f"   ðŸŽ® Board State: Guardado")
            print(f"   ðŸ“Š Score: {vcg_completo['score']}")
            print(f"   ðŸ“š Historia VCG: {len(self.vcg_history)}/{self.max_vcg_history}")

        except Exception as e:
            print(f"âš ï¸ Error al guardar VCG: {e}")

    def choose_action(
        self, frames: list[FrameData], latest_frame: FrameData
    ) -> GameAction:
        """Choose which action the Agent should take, fill in any arguments, and return it."""

        # Mostrar el estado actual del mapa antes de tomar la decisiÃ³n
        self.show_current_map(latest_frame)

        if latest_frame.state in [GameState.NOT_PLAYED, GameState.GAME_OVER]:
            # if game is not started (at init or after GAME_OVER) we need to reset
            # add a small delay before resetting after GAME_OVER to avoid timeout
            action = GameAction.RESET
            action.reasoning = "Reseteando juego por estado inicial o game over"
            print(f"\nðŸ”„ ACCIÃ“N: RESET (automÃ¡tica)")
            return action

        # PRIORIDAD 1: Verificar si hay Ã³rdenes pendientes de LOGOS
        if self.has_pending_orders():
            print(f"\nðŸ“‹ === EJECUTANDO Ã“RDENES PENDIENTES DE LOGOS ===")
            return self._execute_pending_order()

        # PRIORIDAD 2: Si no hay Ã³rdenes pendientes, ejecutar flujo cognitivo completo
        # Ejecutar el flujo cognitivo TOMAS (APEIRON â†’ SOPHIA â†’ LOGOS)
        logos_response, logos_json = self.ask_gemini_analysis(latest_frame)

        # Intentar extraer Ã³rdenes (singular o mÃºltiples) de la respuesta de LOGOS
        action = None
        if logos_json and "command_phase" in logos_json:
            command_phase = logos_json["command_phase"]

            # OPCIÃ“N 1: Verificar si LOGOS devolviÃ³ mÃºltiples Ã³rdenes secuenciales
            if (
                "sequential_orders" in command_phase
                and command_phase["sequential_orders"]
            ):
                ordenes_lista = command_phase["sequential_orders"]
                reasoning = command_phase.get(
                    "chosen_plan_reasoning", "Secuencia de Ã³rdenes de LOGOS"
                )

                if isinstance(ordenes_lista, list) and len(ordenes_lista) > 0:
                    # LOGOS devolviÃ³ mÃºltiples Ã³rdenes - guardarlas para ejecuciÃ³n secuencial
                    self.add_orders_from_logos(ordenes_lista, reasoning)

                    # Ejecutar la primera orden inmediatamente
                    return self._execute_pending_order()

            # OPCIÃ“N 2: Orden Ãºnica (comportamiento original)
            immediate_command = command_phase.get("immediate_command", {})

            if "action" in immediate_command:
                action_command = immediate_command["action"]

                # Mapear comandos de texto a nÃºmeros de acciÃ³n
                action_map = {
                    "move_up": 1,
                    "move_down": 2,
                    "move_left": 3,
                    "move_right": 4,
                    "space": 5,
                    "click": 6,
                }

                suggested_action_number = action_map.get(action_command.lower())

                if suggested_action_number:
                    action = self._map_action_number_to_game_action(
                        suggested_action_number
                    )

                    # Configurar reasoning con toda la informaciÃ³n de LOGOS
                    action.reasoning = {
                        "tomas_flow": "APEIRON â†’ SOPHIA â†’ LOGOS",
                        "execution_mode": "ORDEN_UNICA_LOGOS",
                        "objetivo_turno": logos_json.get("intent_phase", {}).get(
                            "plan_objective", ""
                        ),
                        "decision_final": logos_json.get("choice_phase", {}).get(
                            "final_decision", {}
                        ),
                        "comando_inmediato": immediate_command,
                        "resultado_esperado": logos_json.get(
                            "predictive_judgment_phase", {}
                        ).get("expected_outcome", ""),
                        "suggested_action": suggested_action_number,
                    }

                    print(
                        f"\nâš¡ ACCIÃ“N ÃšNICA DECIDIDA POR LOGOS: {action_command} -> {action.value}"
                    )
                    print(f"ðŸŽ¯ Objetivo: {action.reasoning['objetivo_turno']}")
                    print(
                        f"ðŸ”® Resultado esperado: {action.reasoning['resultado_esperado']}"
                    )

        # Fallback si no se pudo extraer acciÃ³n vÃ¡lida de LOGOS
        if not action:
            print(
                "âš ï¸ No se pudo extraer acciÃ³n vÃ¡lida de LOGOS, usando acciÃ³n aleatoria"
            )
            action = random.choice([a for a in GameAction if a is not GameAction.RESET])
            action.reasoning = {
                "fallback_reason": "Error al extraer acciÃ³n de LOGOS",
                "random_choice": f"AcciÃ³n aleatoria: {action.value}",
                "logos_response_available": logos_json is not None,
            }
            print(f"\nðŸŽ² ACCIÃ“N FALLBACK: {action.value} (aleatoria)")

        if action.is_complex():
            action.set_data(
                {
                    "x": random.randint(0, 63),
                    "y": random.randint(0, 63),
                }
            )

        # Guardar informaciÃ³n para la memoria episÃ³dica
        self._last_frame_before_action = latest_frame
        self._last_action = action
        self._last_gemini_analysis = logos_json

        # Guardar informaciÃ³n de acciÃ³n para el prÃ³ximo anÃ¡lisis espacial
        self.previous_action = (
            action.value
            if hasattr(action, "value") and isinstance(action.value, int)
            else None
        )

        # Extraer coordenadas si es una acciÃ³n compleja
        if action.is_complex() and hasattr(action, "data") and action.data:
            self.previous_action_coordinates = (
                action.data.get("x"),
                action.data.get("y"),
            )
        else:
            self.previous_action_coordinates = None

        print(f"\nâœ… DECISIÃ“N FINAL: {action.value}")
        return action

    def append_frame(self, frame: FrameData) -> None:
        """Override para capturar cambios y actualizar memoria episÃ³dica"""
        super().append_frame(frame)

        # Si tenemos informaciÃ³n de la acciÃ³n anterior, actualizar memoria
        if hasattr(self, "_last_frame_before_action") and hasattr(self, "_last_action"):
            self.add_to_episodic_memory(
                action=self._last_action,
                frame_before=self._last_frame_before_action,
                frame_after=frame,
                gemini_analysis=getattr(self, "_last_gemini_analysis", None),
            )

            # Limpiar variables temporales
            delattr(self, "_last_frame_before_action")
            delattr(self, "_last_action")
            if hasattr(self, "_last_gemini_analysis"):
                delattr(self, "_last_gemini_analysis")
